{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83bb6e5-4edb-433c-aa7b-d50e539f3022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  radius error  texture error  perimeter error  \\\n",
       "0                 0.07871        1.0950         0.9053            8.589   \n",
       "1                 0.05667        0.5435         0.7339            3.398   \n",
       "2                 0.05999        0.7456         0.7869            4.585   \n",
       "3                 0.09744        0.4956         1.1560            3.445   \n",
       "4                 0.05883        0.7572         0.7813            5.438   \n",
       "\n",
       "   area error  smoothness error  compactness error  concavity error  \\\n",
       "0      153.40          0.006399            0.04904          0.05373   \n",
       "1       74.08          0.005225            0.01308          0.01860   \n",
       "2       94.03          0.006150            0.04006          0.03832   \n",
       "3       27.23          0.009110            0.07458          0.05661   \n",
       "4       94.44          0.011490            0.02461          0.05688   \n",
       "\n",
       "   concave points error  symmetry error  fractal dimension error  \\\n",
       "0               0.01587         0.03003                 0.006193   \n",
       "1               0.01340         0.01389                 0.003532   \n",
       "2               0.02058         0.02250                 0.004571   \n",
       "3               0.01867         0.05963                 0.009208   \n",
       "4               0.01885         0.01756                 0.005115   \n",
       "\n",
       "   worst radius  worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "0         25.38          17.33           184.60      2019.0            0.1622   \n",
       "1         24.99          23.41           158.80      1956.0            0.1238   \n",
       "2         23.57          25.53           152.50      1709.0            0.1444   \n",
       "3         14.91          26.50            98.87       567.7            0.2098   \n",
       "4         22.54          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   worst compactness  worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   worst fractal dimension  target  \n",
       "0                  0.11890     0.0  \n",
       "1                  0.08902     0.0  \n",
       "2                  0.08758     0.0  \n",
       "3                  0.17300     0.0  \n",
       "4                  0.07678     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('max_columns', None)\n",
    "\n",
    "# Loading the data and storing it in a pandas DF.\n",
    "breast_cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(np.concatenate((breast_cancer['data'], breast_cancer['target'].reshape(-1,1)), axis=1), \n",
    "                  columns=np.append(breast_cancer['feature_names'], 'target'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72154932-d498-468c-841b-21b002e66abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Separating independent and dependent variables. \n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]#.astype('int')\n",
    "\n",
    "# Creating the train and test sets according to the target variables proportions that were just exposed.\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=.2, random_state=42)\n",
    "for train_index, test_index in split.split(X,y):\n",
    "    train = df.loc[train_index]\n",
    "    test = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4275777e-f071-4820-93d6-09f0f4c4b7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping out the referred columns.\n",
    "to_drop = ['mean smoothness', 'mean symmetry', 'mean fractal dimension', 'texture error',\n",
    "          'smoothness error', 'symmetry error', 'fractal dimension error', 'worst symmetry',\n",
    "          'worst fractal dimension']\n",
    "\n",
    "train.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c4125dc-20df-4bf1-b555-ef8a8e70ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind that the categories have different distribution shapes for each feature. Therefore, the outlier removal needs to be \n",
    "# carried out according to the instance's target variable.\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# We'll avail the occasion to separate the independent and dependent variables.\n",
    "X_train = pd.DataFrame(columns=train.columns[:-1])\n",
    "for target in train.target.unique():\n",
    "    X = zscore(train[train.target==target].iloc[:, :-1]).abs()    \n",
    "    # Only appending to 'X_train' rows that have all their zscore absolute value lower than 3. \n",
    "    X_train = X_train.append(train.loc[X[X<3].dropna().index, :'worst concave points'])\n",
    "    \n",
    "# Creating 'y_train' with the indices from 'X_train'.\n",
    "y_train = train.loc[X_train.index, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1fddeac-153d-4e2d-85ab-ba9189329e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'FeatureFilter' is a class that drops out the features mentioned in the 'to_drop' list.\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class FeatureFilter(BaseException, TransformerMixin):\n",
    "    def __init__(self, to_drop):\n",
    "        # The user needs to pass a list of feature names that need to be disregarded.\n",
    "        self.to_drop = to_drop\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    # Returning the dataset properly trimmed. \n",
    "    def transform(self, X):\n",
    "        # In the training set case, this procedure can't be done, since the features were already trimmed off.\n",
    "        try:\n",
    "            return X.drop(self.to_drop, axis=1)\n",
    "        except:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9280fd88-0b42-48a2-a54e-95ca2c1be320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('filter', FeatureFilter(to_drop)),\n",
    "    ('knn_imputer', KNNImputer(n_neighbors=7)),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "pipe_transformer = pipe.fit(X_train)\n",
    "X_train_transformed = pipe_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c444c3a1-0fc0-4f10-883a-5a50c5180279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeepMostImportant(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'KeepMostImportant()'\n",
    "    \n",
    "    def __init__(self, minimum_importance:float = .01, feature_importances_:list = None):\n",
    "        # 'minimum_importance' is the \n",
    "        self.minimum_importance = minimum_importance\n",
    "        # list of feature importances arrays.\n",
    "        self.feature_importances_ = feature_importances_\n",
    "        \n",
    "    # Fit detects the columns  which their average importance is lower than self.minimum_importance.\n",
    "    def fit(self, X, y=None):\n",
    "        self.__feature_importances_mean = np.mean(self.feature_importances_, axis=0)\n",
    "        self.__keep = np.argwhere(self.__feature_importances_mean > self.minimum_importance).reshape(1, -1).ravel()\n",
    "        return self\n",
    "    \n",
    "    # 'transform' returns the features array without the irrelevant columns.\n",
    "    def transform(self, X):\n",
    "        return X[:, self.__keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fa3ebf2-ac67-44e3-8ef5-b10f35376228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "xgb = load('models/xgboost.joblib')\n",
    "xgb_importances = xgb.feature_importances_\n",
    "\n",
    "extra = load('models/extra_trees.joblib')\n",
    "extra_importances = extra.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32ea057a-8b3e-478e-848c-111f3d405820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a second pipe with 'pipe' and our new transformator.\n",
    "pipe2 = Pipeline([\n",
    "    ('pipe', pipe),\n",
    "    ('keep_most_important', KeepMostImportant(feature_importances_=[xgb_importances, extra_importances]))\n",
    "    ])\n",
    "\n",
    "# Removing the irrelevant columns.\n",
    "X_train_transformed2 = pipe2.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7b8f2b5-fc38-45fe-b237-86cbf937810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = load('models/kmeans.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2d7cbc1-fac4-41c9-88be-7c557bcbf710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "def get_nearest_centroids_neighbors(X:'array'=None, y:'array'=None, kmeans:KMeans=None, n:int=1):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    instances = []\n",
    "    # The KNN algorithm below identifies the n-nearest instances to the centroids.\n",
    "    knn = KNeighborsClassifier().fit(X,y)\n",
    "    \n",
    "    # For each cluster created, locate the n-nearest neighbors of the respective centroids and append them to 'instances'..\n",
    "    for i in np.unique(kmeans.labels_).astype('int'):\n",
    "        instances.extend(knn.kneighbors(kmeans.cluster_centers_[i].reshape(1, -1), n_neighbors=n, return_distance=False).ravel())\n",
    "        \n",
    "    # Returning the X and y arrays with only the data of the centroids' n-nearest neighbors.\n",
    "    print(instances)\n",
    "    return X[instances], y[instances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e00eff53-3d17-4d0a-86d4-7bfe799a3686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115, 405]\n"
     ]
    }
   ],
   "source": [
    "# As initially proposed, getting the top-1 closest instances to each centroid.\n",
    "X_nn, y_nn = get_nearest_centroids_neighbors(X=X_train_transformed2,  y=y_train.values, kmeans=kmeans, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dfc865c-fb02-4cd3-9935-1bbc0dd4fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = load('models/svm.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7f33cc8-1ee6-4b2a-8623-53f7b6697efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before any validation is made, it is important to transform the dataset to the training format.\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]\n",
    "\n",
    "# Now applying the pipeline transformations in the 'X_test' variable.\n",
    "X_test_transformed = pipe2.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b815e020-2e47-461e-807c-dac8fc901c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9490345446046117"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "fbeta_score(y_test,svm.predict(X_test_transformed), beta=.37)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
